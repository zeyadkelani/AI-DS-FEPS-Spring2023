{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bc6ef7",
   "metadata": {},
   "source": [
    "## Sentiment Analysis \n",
    "\n",
    "In today's section, we will cover how to carry out an unsupervised, lexicon-based sentiment analysis. \n",
    "\n",
    "Usually, before applying text analysis tools (sentiment analysis, topic modeling...), we need to do some web scraping, or a Twitter API query. You can refer to Duke University's research guide for Introduction to Text Analysis tools to have a more comprehensive view on possible text analyses: https://guides.library.duke.edu/text_analysis\n",
    "\n",
    "Some important resources to get you started on web scraping using Python's Beautiful Soup:\n",
    "- https://opensource.com/article/21/9/web-scraping-python-beautiful-soup\n",
    "- https://gitlab.com/ayush-sharma/example-assets/-/blob/fd7d2dfbfa3ca34103402993b35a61cbe943bcf3/programming/beautiful-soup/fetch.py\n",
    "- https://www.geeksforgeeks.org/implementing-web-scraping-python-beautiful-soup/\n",
    "- https://stackoverflow.com/a/40629823 [A useful stackoverflow on how to web scrape multiple URLs instead of just one as demonstrated in the examples above]\n",
    "\n",
    "Twitter API used to be open and free for academic research. Unfortunately, currently the Twitter API is down/will start charging for the queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e551897",
   "metadata": {},
   "source": [
    "Sentiment analysis, a popular Natural Language Processing (NLP) task, has a goal of classifying text based on the sentiment/mood/emotional implications of the words expressed in the text. It can be positive, negative, or neutral (polarity), but it can also focus on emotions (such as happy, sad, angry...etc). \n",
    "\n",
    "Sentiment analysis can be carried out using various NLP algorithms.\n",
    "\n",
    "Another useful tutorial that applies a lexicon-based algorithm (unsupervised) and supervised ML techniques to carry out a sentiment analysis and also covers some of the necessary pre-processing steps: https://towardsdatascience.com/nlp-sentiment-analysis-for-beginners-e7897f976897 \n",
    "\n",
    "Another tutorial that covers lexicon-based algorithms/unsupervised ML techniques, evaluates their performances, and compares their performance on movie reviews data: https://github.com/mohammed97ashraf/Sentiment-Analysis-Using-Unsupervised-Lexical-Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4721ba",
   "metadata": {},
   "source": [
    "Out of the techniques covered in the aforementioned tutorials, we will cover VADER, Valence Aware Dictionary and sEntiment Reasoner, lexicon and simple rule-based model for sentiment analysis.\n",
    "\n",
    "It can efficiently handle vocabularies, abbreviations, capitalizations, repeated punctuations, emoticons (ðŸ˜¢ , ðŸ˜ƒ , ðŸ˜­ , etc.), etc. usually adopted on social media platforms to express oneâ€™s sentiment, which makes it a great fit for **social media sentiment text analysis.**\n",
    "\n",
    "- No training needed; ready to use and assess the sentiment of any given text. \n",
    "- The results of VADER include: neg (negative), neu (neutral), pos(positive) and compound. \n",
    "- neg, neu, pos should sum up to 1 or approximately 1.\n",
    "- compound is the sum of the valence/polarity score of each word in the lexicon and determines the *degree* of the sentiment not just its direction/actual value; it ranges from -1 (very negative sentiment) to 1 (very positive sentiment).\n",
    "    - So basically, the compound score is the sum of positive, negative & neutral scores which is then normalized between -1(most extreme negative) and +1 (most extreme positive)\n",
    "- We can use the compound score to determine the underlying sentiment, good rule of thumb:\n",
    "- a positive sentiment, compound â‰¥ 0.05\n",
    "- a negative sentiment, compound â‰¤ -0.05\n",
    "- a neutral sentiment, the compound is between ]-0.05, 0.05["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed2e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\noura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import nltk # Natural Language Toolkit, documentation: https://www.nltk.org/\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download VADER lexicon\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Import the lexicon\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79811a5",
   "metadata": {},
   "source": [
    "A senti-lexicon is, in very simple terms, a dictionary of words and their associated sentiment. \n",
    "\n",
    "The VADER Lexicon documentation can be found here: https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "Documentation for nltk.sentiment.vader: https://www.nltk.org/api/nltk.sentiment.vader.html#module-nltk.sentiment.vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f075c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of SentimentIntensityAnalyzer uploaded above\n",
    "\n",
    "SentimentAnalyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c1e35",
   "metadata": {},
   "source": [
    "An important function when using the SentimentIntensityAnalyzer:\n",
    "\n",
    "**SentimentIntensityAnalyzer.polarity_score()** function provides the polarity of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b61038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 has polarity scores of {'neg': 0.0, 'neu': 0.695, 'pos': 0.305, 'compound': 0.6588}\n",
      "Sentence 2 has polarity scores of {'neg': 0.0, 'neu': 0.373, 'pos': 0.627, 'compound': 0.8284}\n",
      "Sentence 3 has polarity scores of {'neg': 0.703, 'neu': 0.297, 'pos': 0.0, 'compound': -0.9163}\n"
     ]
    }
   ],
   "source": [
    "# Some examples to demonstrate our SentimentAnalyzer:\n",
    "\n",
    "sentence1 = \"VADER is great at identifying the sentiment of a social media post!\"\n",
    "\n",
    "print(\"Sentence 1 has polarity scores of\", SentimentAnalyzer.polarity_scores(sentence1))\n",
    "\n",
    "sentence2 =  \"VADER is a REALLY AMAZING library!!!!\"\n",
    "\n",
    "print(\"Sentence 2 has polarity scores of\", SentimentAnalyzer.polarity_scores(sentence2))\n",
    "\n",
    "sentence3= \"I HATE fake news on the internet, so frustrating!!\"\n",
    "\n",
    "print(\"Sentence 3 has polarity scores of\", SentimentAnalyzer.polarity_scores(sentence3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe8d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onto applying VADER on a license-free tweets dataset available on http://help.sentiment140.com/for-students\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/keitazoumana/VADER_sentiment-Analysis/main/data/testdata.manual.2009.06.14.csv\"\n",
    "\n",
    "sentiment_data = pd.read_csv(data_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e689cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>Mon May 11 03:17:40 UTC 2009</th>\n",
       "      <th>kindle2</th>\n",
       "      <th>tpryan</th>\n",
       "      <th>@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  3  Mon May 11 03:17:40 UTC 2009  kindle2        tpryan  \\\n",
       "0  4  4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1  4  5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2  4  6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3  4  7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4  4  8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "  @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...                                                               \n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...                                                               \n",
       "2  @kenburbary You'll love your Kindle2. I've had...                                                               \n",
       "3  @mikefish  Fair enough. But i have the Kindle2...                                                               \n",
       "4  @richardebaker no. it is too big. I'm quite ha...                                                               "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba70c4c",
   "metadata": {},
   "source": [
    "We only care about the last column: the actual tweet, and the 1st column with 4: the polarity of the tweet. The polarity in this dataset is expressed such as 0 is negative, 2 is neutral, and 4 is positive. \n",
    "\n",
    "This dataset is annotated with the polarity of each tweet to work as a validator for the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca477372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  polarity\n",
       "0  Reading my kindle2...  Love it... Lee childs i...  positive\n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...  positive\n",
       "2  @kenburbary You'll love your Kindle2. I've had...  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_data(data):\n",
    "\n",
    "  last_col = str(data.columns[-1])\n",
    "  first_col = str(data.columns[0])\n",
    "\n",
    "  data.rename(columns = {last_col: 'tweet_text', first_col: 'polarity'}, inplace=True) \n",
    "\n",
    "  # Change 0, 2, 4 to negative, neutral and positive\n",
    "  labels = {0: 'negative', 2: 'neutral', 4: 'positive'}\n",
    "  data['polarity'] = data['polarity'].map(labels)\n",
    "\n",
    "  # Get only the two columns\n",
    "  return data[['tweet_text', 'polarity']]\n",
    "\n",
    "# Apply the transformation\n",
    "data = format_data(sentiment_data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d595472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noura\\AppData\\Local\\Temp\\ipykernel_18636\\3325896253.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"vader_prediction_polarity1\"] = data.loc[:,(\"tweet_text\")].apply(predict_sentiment1)\n",
      "C:\\Users\\noura\\AppData\\Local\\Temp\\ipykernel_18636\\3325896253.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"vader_prediction_polarity2\"] = data.loc[:,(\"tweet_text\")].apply(predict_sentiment2)\n"
     ]
    }
   ],
   "source": [
    "def format_output(output_dict):\n",
    "  \n",
    "  polarity = \"neutral\"\n",
    "\n",
    "  if(output_dict['compound']>= 0.05):\n",
    "    polarity = \"positive\"\n",
    "\n",
    "  elif(output_dict['compound']<= -0.05):\n",
    "    polarity = \"negative\"\n",
    "\n",
    "  return polarity\n",
    "\n",
    "def predict_sentiment1(text):\n",
    "  \n",
    "  output_dict =  SentimentAnalyzer.polarity_scores(text)\n",
    "  return format_output(output_dict)\n",
    "\n",
    "def predict_sentiment2(text):\n",
    "  \n",
    "  output_dict =  SentimentAnalyzer.polarity_scores(text)\n",
    "  return output_dict\n",
    "\n",
    "# Run the predictions\n",
    "data[\"vader_prediction_polarity1\"] = data.loc[:,(\"tweet_text\")].apply(predict_sentiment1)\n",
    "\n",
    "text = data[\"tweet_text\"]\n",
    "data[\"vader_prediction_polarity2\"] = data.loc[:,(\"tweet_text\")].apply(predict_sentiment2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0129d157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>vader_prediction_polarity1</th>\n",
       "      <th>vader_prediction_polarity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>yankees won mets lost. its a good day.</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.178, 'neu': 0.31, 'pos': 0.512, 'compound': 0.6486}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>@uscsports21 LeBron is a monsta and he is only 24. SMH The world ain't ready.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'neg': 0.3, 'neu': 0.7, 'pos': 0.0, 'compound': -0.6301}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ugh. the amount of times these stupid insects have bitten me. Grr..</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'neg': 0.383, 'neu': 0.617, 'pos': 0.0, 'compound': -0.7351}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i love lebron. http://bit.ly/PdHur</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>this dentist's office is cold :/</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'neg': 0.324, 'neu': 0.676, 'pos': 0.0, 'compound': -0.34}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        tweet_text  \\\n",
       "403                                         yankees won mets lost. its a good day.   \n",
       "255  @uscsports21 LeBron is a monsta and he is only 24. SMH The world ain't ready.   \n",
       "333            ugh. the amount of times these stupid insects have bitten me. Grr..   \n",
       "16                                              i love lebron. http://bit.ly/PdHur   \n",
       "409                                               this dentist's office is cold :/   \n",
       "\n",
       "     polarity vader_prediction_polarity1  \\\n",
       "403  positive                   positive   \n",
       "255  positive                   negative   \n",
       "333  negative                   negative   \n",
       "16   positive                   positive   \n",
       "409  negative                   negative   \n",
       "\n",
       "                                        vader_prediction_polarity2  \n",
       "403  {'neg': 0.178, 'neu': 0.31, 'pos': 0.512, 'compound': 0.6486}  \n",
       "255      {'neg': 0.3, 'neu': 0.7, 'pos': 0.0, 'compound': -0.6301}  \n",
       "333  {'neg': 0.383, 'neu': 0.617, 'pos': 0.0, 'compound': -0.7351}  \n",
       "16    {'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}  \n",
       "409    {'neg': 0.324, 'neu': 0.676, 'pos': 0.0, 'compound': -0.34}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "# Show 5 random rows of the data\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2e000d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716297786720322\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.64      0.72       177\n",
      "     neutral       0.67      0.70      0.68       139\n",
      "    positive       0.67      0.81      0.73       181\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.73      0.71      0.71       497\n",
      "weighted avg       0.73      0.72      0.72       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating VADER based on original polarity and VADER-predicted polarity\n",
    "\n",
    "accuracy = accuracy_score(data['polarity'], data['vader_prediction_polarity1'])\n",
    "\n",
    "print(\"Accuracy: {}\\n\".format(accuracy))\n",
    "\n",
    "# Show the classification report\n",
    "\n",
    "print(classification_report(data['polarity'], data['vader_prediction_polarity1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203cb7a",
   "metadata": {},
   "source": [
    "- Precision attempts to answer the following question: What proportion of positive identifications was actually correct?\n",
    "\n",
    "- Recall attempts to answer the following question: What proportion of actual positives was identified correctly?\n",
    "\n",
    "- A good F1 score (a ML metric that is used in classification models) means that you have low false positives and low false negatives, so you're correctly identifying real threats and you are not disturbed by false alarms. An F1 score is considered perfect when it's 1 , while the model is a total failure when it's 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
